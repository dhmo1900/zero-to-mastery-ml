{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸšœ Predicting the Sale Price of Bulldozers using Machine Learning \n",
    "\n",
    "In this notebook, we're going to go through an example machine learning project with the goal of predicting the sale price of bulldozers.\n",
    "\n",
    "Since we're trying to predict a number, this kind of problem is known as a **regression problem**.\n",
    "\n",
    "The data and evaluation metric we'll be using (root mean square log error or RMSLE) is from the [Kaggle Bluebook for Bulldozers competition](https://www.kaggle.com/c/bluebook-for-bulldozers/overview).\n",
    "\n",
    "The techniques used in here have been inspired and adapted from [the fast.ai machine learning course](https://course18.fast.ai/ml).\n",
    "\n",
    "## What we'll end up with\n",
    "\n",
    "Since we already have a dataset, we'll approach the problem with the following machine learning modelling framework.\n",
    "\n",
    "| <img src=\"../images/ml101-6-step-ml-framework.png\" width=500/> | \n",
    "|:--:| \n",
    "| 6 Step Machine Learning Modelling Framework ([read more](https://whimsical.com/9g65jgoRYTxMXxDosndYTB)) |\n",
    "\n",
    "To work through these topics, we'll use pandas, Matplotlib and NumPy for data anaylsis, as well as, Scikit-Learn for machine learning and modelling tasks.\n",
    "\n",
    "| <img src=\"../images/supervised-projects-6-step-ml-framework-tools-highlight.png\" width=500/> | \n",
    "|:--:| \n",
    "| Tools which can be used for each step of the machine learning modelling process. |\n",
    "\n",
    "We'll work through each step and by the end of the notebook, we'll have a trained machine learning model which predicts the sale price of a bulldozer given different characteristics about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Definition\n",
    "\n",
    "For this dataset, the problem we're trying to solve, or better, the question we're trying to answer is,\n",
    "\n",
    "> How well can we predict the future sale price of a bulldozer, given its characteristics previous examples of how much similar bulldozers have been sold for?\n",
    "\n",
    "## 2. Data\n",
    "\n",
    "Looking at the [dataset from Kaggle](https://www.kaggle.com/c/bluebook-for-bulldozers/data), you can you it's a time series problem. This means there's a time attribute to dataset.\n",
    "\n",
    "In this case, it's historical sales data of bulldozers. Including things like, model type, size, sale date and more.\n",
    "\n",
    "There are 3 datasets:\n",
    "1. **Train.csv** - Historical bulldozer sales examples up to 2011 (close to 400,000 examples with 50+ different attributes, including `SalePrice` which is the **target variable**).\n",
    "2. **Valid.csv** - Historical bulldozer sales examples from January 1 2012 to April 30 2012 (close to 12,000 examples with the same attributes as **Train.csv**).\n",
    "3. **Test.csv** - Historical bulldozer sales examples from May 1 2012 to November 2012 (close to 12,000 examples but missing the `SalePrice` attribute, as this is what we'll be trying to predict).\n",
    "\n",
    "## 3. Evaluation\n",
    "\n",
    "For this problem, [Kaggle has set the evaluation metric to being root mean squared log error (RMSLE)](https://www.kaggle.com/c/bluebook-for-bulldozers/overview/evaluation). As with many regression evaluations, the goal will be to get this value as low as possible.\n",
    "\n",
    "To see how well our model is doing, we'll calculate the RMSLE and then compare our results to others on the [Kaggle leaderboard](https://www.kaggle.com/c/bluebook-for-bulldozers/leaderboard).\n",
    "\n",
    "## 4. Features\n",
    "\n",
    "Features are different parts of the data. During this step, you'll want to start finding out what you can about the data.\n",
    "\n",
    "One of the most common ways to do this, is to create a **data dictionary**.\n",
    "\n",
    "For this dataset, Kaggle provide a data dictionary which contains information about what each attribute of the dataset means. You can [download this file directly from the Kaggle competition page](https://www.kaggle.com/c/bluebook-for-bulldozers/download/Bnl6RAHA0enbg0UfAvGA%2Fversions%2FwBG4f35Q8mAbfkzwCeZn%2Ffiles%2FData%20Dictionary.xlsx) (account required) or view it on Google Sheets.\n",
    "\n",
    "With all of this being known, let's get started! \n",
    "\n",
    "First, we'll import the dataset and start exploring. Since we know the evaluation metric we're trying to minimise, our first goal will be building a baseline model and seeing how it stacks up against the competition.\n",
    "\n",
    "### Importing the data and preparing it for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data analysis tools \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got our tools for data analysis ready, we can import the data and start to explore it.\n",
    "\n",
    "For this project, we've [downloaded the data from Kaggle](https://www.kaggle.com/c/bluebook-for-bulldozers/data) and stored it under the file path `\"../data/\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the training and validation set\n",
    "df = pd.read_csv(\"../data/bluebook-for-bulldozers/TrainAndValid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No parse_dates... check dtype of \"saledate\"\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df[\"saledate\"][:1000], df[\"SalePrice\"][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SalePrice.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing dates\n",
    "When working with time series data, it's a good idea to make sure any date data is the format of a [datetime object](https://docs.python.org/3/library/datetime.html) (a Python data type which encodes specific information about dates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/bluebook-for-bulldozers/TrainAndValid.csv\",\n",
    "                 low_memory=False,\n",
    "                 parse_dates=[\"saledate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With parse_dates... check dtype of \"saledate\"\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df[\"saledate\"][:1000], df[\"SalePrice\"][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort DataFrame by saledate\n",
    "\n",
    "As we're working on a time series problem and trying to predict future examples given past examples, it makes sense to sort our data by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort DataFrame in date order\n",
    "df.sort_values(by=[\"saledate\"], inplace=True, ascending=True)\n",
    "df.saledate.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a copy of the original DataFrame\n",
    "\n",
    "Since we're going to be manipulating the data, we'll make a copy of the original DataFrame and perform our changes there.\n",
    "\n",
    "This will keep the original DataFrame in tact if we need it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the original DataFrame to perform edits on\n",
    "df_tmp = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add datetime parameters for saledate column\n",
    "\n",
    "Why?\n",
    "\n",
    "So we can enrich our dataset with as much information as possible.\n",
    "\n",
    "Because we imported the data using `read_csv()` and we asked pandas to parse the dates using `parase_dates=[\"saledate\"]`, we can now access the [different datetime attributes](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.html) of the `saledate` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add datetime parameters for saledate\n",
    "df_tmp[\"saleYear\"] = df_tmp.saledate.dt.year\n",
    "df_tmp[\"saleMonth\"] = df_tmp.saledate.dt.month\n",
    "df_tmp[\"saleDay\"] = df_tmp.saledate.dt.day\n",
    "df_tmp[\"saleDayofweek\"] = df_tmp.saledate.dt.dayofweek\n",
    "df_tmp[\"saleDayofyear\"] = df_tmp.saledate.dt.dayofyear\n",
    "\n",
    "# Drop original saledate\n",
    "df_tmp.drop(\"saledate\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could add more of these style of columns, such as, whether it was the start or end of a quarter but these will do for now.\n",
    "\n",
    "**Challenge:** See what other [datetime attributes](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.html) you can add to `df_tmp` using a similar technique to what we've used above. Hint: check the bottom of the pandas.DatetimeIndex docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the different values of different columns\n",
    "df_tmp.state.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling\n",
    "\n",
    "We've explored our dataset a little as well as enriched it with some datetime attributes, now let's try to model.\n",
    "\n",
    "Why model so early?\n",
    "\n",
    "We know the evaluation metric we're heading towards. We could spend more time doing exploratory data analysis (EDA), finding more out about the data ourselves but what we'll do instead is use a machine learning model to help us do EDA.\n",
    "\n",
    "Remember, one of the biggest goals of starting any new machine learning project is reducing the time between experiments.\n",
    "\n",
    "Following the [Scikit-Learn machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html), we find a [RandomForestRegressor()](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn-ensemble-randomforestregressor) might be a good candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This won't work since we've got missing numbers and categories\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_jobs=-1)\n",
    "model.fit(df_tmp.drop(\"SalePrice\", axis=1), df_tmp.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing categories and different datatypes\n",
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df_tmp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert strings to categories\n",
    "\n",
    "One way to help turn all of our data into numbers is to convert the columns with the string datatype into a category datatype.\n",
    "\n",
    "To do this we can use the [pandas types API](https://pandas.pydata.org/pandas-docs/stable/reference/general_utility_functions.html#data-types-related-functionality) which allows us to interact and manipulate the types of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.api.types.is_string_dtype(df_tmp[\"UsageBand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These columns contain strings\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're wondering what df.items() does, let's use a dictionary as an example\n",
    "random_dict = {\"key1\": \"hello\",\n",
    "               \"key2\": \"world!\"}\n",
    "\n",
    "for key, value in random_dict.items():\n",
    "    print(f\"This is a key: {key}\")\n",
    "    print(f\"This is a value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will turn all of the string values into category values\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        df_tmp[label] = content.astype(\"category\").cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.state.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.state.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our data is categorical and thus we can now turn the categories into numbers, however it's still missing values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.isnull().sum()/len(df_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the format it's in, it's still good to be worked with, let's save it to file and reimport it so we can continue on.\n",
    "\n",
    "### Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data\n",
    "df_tmp.to_csv(\"../data/bluebook-for-bulldozers/train_tmp.csv\",\n",
    "              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessed data\n",
    "df_tmp = pd.read_csv(\"../data/bluebook-for-bulldozers/train_tmp.csv\",\n",
    "                     low_memory=False)\n",
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, our processed DataFrame has the columns we added to it but it's still missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "df_tmp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill missing values\n",
    "\n",
    "From our experience with machine learning models. We know two things:\n",
    "1. All of our data has to be numerical\n",
    "2. There can't be any missing values\n",
    "\n",
    "And as we've seen using `df_tmp.isna().sum()` our data still has plenty of missing values.\n",
    "\n",
    "Let's fill them.\n",
    "\n",
    "### Filling numerical values first\n",
    "\n",
    "We're going to fill any column with missing values with the median of that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for which numeric columns have null values\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill numeric rows with the median\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            # Add a binary column which tells if the data was missing our not\n",
    "            df_tmp[label+\"_is_missing\"] = pd.isnull(content)\n",
    "            # Fill missing numeric values with median since it's more robust than the mean\n",
    "            df_tmp[label] = content.fillna(content.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why add a binary column indicating whether the data was missing or not?\n",
    "\n",
    "We can easily fill all of the missing numeric values in our dataset with the median. However, a numeric value may be missing for a reason. In other words, absence of evidence may be evidence of absence. Adding a binary column which indicates whether the value was missing or not helps to retain this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there's any null values\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see how many examples were missing\n",
    "df_tmp.auctioneerID_is_missing.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling and turning categorical variables to numbers\n",
    "\n",
    "Now we've filled the numeric values, we'll do the same with the categorical values at the same time as turning them into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns which *aren't* numeric\n",
    "for label, content in df_tmp.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn categorical variables into numbers\n",
    "for label, content in df_tmp.items():\n",
    "    # Check columns which *aren't* numeric\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        # Add binary column to inidicate whether sample had missing value\n",
    "        df_tmp[label+\"_is_missing\"] = pd.isnull(content)\n",
    "        # We add the +1 because pandas encodes missing categories as -1\n",
    "        df_tmp[label] = pd.Categorical(content).codes+1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all of our data is numeric and there are no missing values, we should be able to build a machine learning model!\n",
    "\n",
    "Let's reinstantiate our trusty [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html).\n",
    "\n",
    "This will take a few minutes which is too long for interacting with it. So what we'll do is create a subset of rows to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate model\n",
    "model = RandomForestRegressor(n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(df_tmp.drop(\"SalePrice\", axis=1), df_tmp.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the model\n",
    "model.score(df_tmp.drop(\"SalePrice\", axis=1), df_tmp.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why is this metric not reliable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into train/valid sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the [Kaggle data page](https://www.kaggle.com/c/bluebook-for-bulldozers/data), the validation set and test set are split according to dates.\n",
    "\n",
    "This makes sense since we're working on a time series problem.\n",
    "\n",
    "E.g. using past events to try and predict future events.\n",
    "\n",
    "Knowing this, randomly splitting our data into train and test sets using something like `train_test_split()` wouldn't work.\n",
    "\n",
    "Instead, we split our data into training, validation and test sets using the date each sample occured.\n",
    "\n",
    "In our case:\n",
    "* Training = all samples up until 2011\n",
    "* Valid = all samples form January 1, 2012 - April 30, 2012\n",
    "* Test = all samples from May 1, 2012 - November 2012\n",
    "\n",
    "For more on making good training, validation and test sets, check out the post [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/) by Rachel Thomas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.saleYear.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation\n",
    "df_val = df_tmp[df_tmp.saleYear == 2012]\n",
    "df_train = df_tmp[df_tmp.saleYear != 2012]\n",
    "\n",
    "len(df_val), len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X & y\n",
    "X_train, y_train = df_train.drop(\"SalePrice\", axis=1), df_train.SalePrice\n",
    "X_valid, y_valid = df_val.drop(\"SalePrice\", axis=1), df_val.SalePrice\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an evaluation function\n",
    "\n",
    "According to Kaggle for the Bluebook for Bulldozers competition, [the evaluation function](https://www.kaggle.com/c/bluebook-for-bulldozers/overview/evaluation) they use is root mean squared log error (RMSLE).\n",
    "\n",
    "**RMSLE** = generally you don't care as much if you're off by $10 as much as you'd care if you were off by 10%, you care more about ratios rather than differences. **MAE** (mean absolute error) is more about exact differences.\n",
    "\n",
    "It's important to understand the evaluation metric you're going for.\n",
    "\n",
    "Since Scikit-Learn doesn't have a function built-in for RMSLE, we'll create our own.\n",
    "\n",
    "We can do this by taking the square root of Scikit-Learn's [mean_squared_log_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_log_error.html#sklearn.metrics.mean_squared_log_error) (MSLE). MSLE is the same as taking the log of mean squared error (MSE).\n",
    "\n",
    "We'll also calculate the MAE and R^2 for fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation function (the competition uses Root Mean Square Log Error)\n",
    "from sklearn.metrics import mean_squared_log_error, mean_absolute_error\n",
    "\n",
    "def rmsle(y_test, y_preds):\n",
    "    return np.sqrt(mean_squared_log_error(y_test, y_preds))\n",
    "\n",
    "# Create function to evaluate our model\n",
    "def show_scores(model):\n",
    "    train_preds = model.predict(X_train)\n",
    "    val_preds = model.predict(X_valid)\n",
    "    scores = {\"Training MAE\": mean_absolute_error(y_train, train_preds),\n",
    "              \"Valid MAE\": mean_absolute_error(y_valid, val_preds),\n",
    "              \"Training RMSLE\": rmsle(y_train, train_preds),\n",
    "              \"Valid RMSLE\": rmsle(y_valid, val_preds),\n",
    "              \"Training R^2\": model.score(X_train, y_train),\n",
    "              \"Valid R^2\": model.score(X_valid, y_valid)}\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our model on a subset (to tune the hyperparameters)\n",
    "\n",
    "Retraing an entire model would take far too long to continuing experimenting as fast as we want to.\n",
    "\n",
    "So what we'll do is take a sample of the training set and tune the hyperparameters on that before training a larger model.\n",
    "\n",
    "If you're experiments are taking longer than 10-seconds (give or take how long you have to wait), you should be trying to speed things up. You can speed things up by sampling less data or using a faster computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes too long...\n",
    "\n",
    "# %%time\n",
    "# # Retrain a model on training data\n",
    "# model.fit(X_train, y_train)\n",
    "# show_scores(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your computer (mine is a MacBook Pro), making calculations on ~400,000 rows may take a while...\n",
    "\n",
    "Let's alter the number of samples each `n_estimator` in the [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) see's using the `max_samples` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change max samples in RandomForestRegressor\n",
    "model = RandomForestRegressor(n_jobs=-1,\n",
    "                              max_samples=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting `max_samples` to 10000 means every `n_estimator` (default 100) in our `RandomForestRegressor` will only see 10000 random samples from our DataFrame instead of the entire 400,000.\n",
    "\n",
    "In other words, we'll be looking at 40x less samples which means we'll get faster computation speeds but we should expect our results to worsen (simple the model has less samples to learn patterns from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cutting down the max number of samples each tree can see improves training time\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful, that took far less time than the model with all the data.\n",
    "\n",
    "With this, let's try tune some hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with RandomizedSearchCV\n",
    "\n",
    "You can increase `n_iter` to try more combinations of hyperparameters but in our case, we'll try 20 and see where it gets us.\n",
    "\n",
    "Remember, we're trying to reduce the amount of time it takes between experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Different RandomForestClassifier hyperparameters\n",
    "rf_grid = {\"n_estimators\": np.arange(10, 100, 10),\n",
    "           \"max_depth\": [None, 3, 5, 10],\n",
    "           \"min_samples_split\": np.arange(2, 20, 2),\n",
    "           \"min_samples_leaf\": np.arange(1, 20, 2),\n",
    "           \"max_features\": [0.5, 1, \"sqrt\", \"auto\"],\n",
    "           \"max_samples\": [10000]}\n",
    "\n",
    "rs_model = RandomizedSearchCV(RandomForestRegressor(),\n",
    "                              param_distributions=rf_grid,\n",
    "                              n_iter=20,\n",
    "                              cv=5,\n",
    "                              verbose=True)\n",
    "\n",
    "rs_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best parameters from the RandomizedSearch \n",
    "rs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the RandomizedSearch model\n",
    "show_scores(rs_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model with the best parameters\n",
    "\n",
    "In a model I prepared earlier, I tried 100 different combinations of hyperparameters (setting `n_iter` to 100 in `RandomizedSearchCV`) and found the best results came from the ones you see below.\n",
    "\n",
    "**Note:** This kind of search on my computer (`n_iter` = 100) took ~2-hours. So it's kind of a set and come back later experiment.\n",
    "\n",
    "We'll instantiate a new model with these discovered hyperparameters and reset the `max_samples` back to its original value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Most ideal hyperparameters\n",
    "ideal_model = RandomForestRegressor(n_estimators=90,\n",
    "                                    min_samples_leaf=1,\n",
    "                                    min_samples_split=14,\n",
    "                                    max_features=0.5,\n",
    "                                    n_jobs=-1,\n",
    "                                    max_samples=None)\n",
    "ideal_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(ideal_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these new hyperparameters as well as using all the samples, we can see an improvement to our models performance.\n",
    "\n",
    "You can make a faster model by altering some of the hyperparameters. Particularly by lowering `n_estimators` since each increase in `n_estimators` is basically building another small model.\n",
    "\n",
    "However, lowering of `n_estimators` or altering of other hyperparameters may lead to poorer results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Faster model\n",
    "fast_model = RandomForestRegressor(n_estimators=40,\n",
    "                                   min_samples_leaf=3,\n",
    "                                   max_features=0.5,\n",
    "                                   n_jobs=-1)\n",
    "fast_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(fast_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on test data\n",
    "\n",
    "Now we've got a trained model, it's time to make predictions on the test data.\n",
    "\n",
    "Remember what we've done.\n",
    "\n",
    "Our model is trained on data prior to 2011. However, the test data is from May 1 2012 to November 2012.\n",
    "\n",
    "So what we're doing is trying to use the patterns our model has learned in the training data to predict the sale price of a Bulldozer with characteristics it's never seen before but are assumed to be similar to that of those in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../data/bluebook-for-bulldozers/Test.csv\",\n",
    "                      parse_dates=[\"saledate\"])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how the model goes predicting on the test data\n",
    "model.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahhh... the test data isn't in the same format of our other data, so we have to fix it. Let's create a function to preprocess our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data\n",
    "\n",
    "Our model has been trained on data formatted in the same way as the training data.\n",
    "\n",
    "This means in order to make predictions on the test data, we need to take the same steps we used to preprocess the training data to preprocess the test data.\n",
    "\n",
    "Remember: Whatever you do to the training data, you have to do to the test data.\n",
    "\n",
    "Let's create a function for doing so (by copying the preprocessing steps we used above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Add datetime parameters for saledate\n",
    "    df[\"saleYear\"] = df.saledate.dt.year\n",
    "    df[\"saleMonth\"] = df.saledate.dt.month\n",
    "    df[\"saleDay\"] = df.saledate.dt.day\n",
    "    df[\"saleDayofweek\"] = df.saledate.dt.dayofweek\n",
    "    df[\"saleDayofyear\"] = df.saledate.dt.dayofyear\n",
    "\n",
    "    # Drop original saledate\n",
    "    df.drop(\"saledate\", axis=1, inplace=True)\n",
    "    \n",
    "    # Fill numeric rows with the median\n",
    "    for label, content in df.items():\n",
    "        if pd.api.types.is_numeric_dtype(content):\n",
    "            if pd.isnull(content).sum():\n",
    "                df[label+\"_is_missing\"] = pd.isnull(content)\n",
    "                df[label] = content.fillna(content.median())\n",
    "                \n",
    "        # Turn categorical variables into numbers\n",
    "        if not pd.api.types.is_numeric_dtype(content):\n",
    "            df[label+\"_is_missing\"] = pd.isnull(content)\n",
    "            # We add the +1 because pandas encodes missing categories as -1\n",
    "            df[label] = pd.Categorical(content).codes+1        \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Where would this function break?\n",
    "\n",
    "**Hint:** What if the test data had different missing values to the training data?\n",
    "\n",
    "Now we've got a function for preprocessing data, let's preprocess the test dataset into the same format as our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = preprocess_data(df_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test dataset using the best model\n",
    "test_preds = ideal_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've found an error and it's because our test dataset (after preprocessing) has 101 columns where as, our training dataset (`X_train`) has 102 columns (after preprocessing).\n",
    "\n",
    "Let's find the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can find how the columns differ using sets\n",
    "set(X_train.columns) - set(df_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it's because the test dataset wasn't missing any `auctioneerID` fields.\n",
    "\n",
    "To fix it, we'll add a column to the test dataset called `auctioneerID_is_missing` and fill it with `False`, since none of the `auctioneerID` fields are missing in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match test dataset columns to training dataset\n",
    "df_test[\"auctioneerID_is_missing\"] = False\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the test dataset matches the training dataset, we should be able to make predictions on it using our trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test dataset using the best model\n",
    "test_preds = ideal_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the [Kaggle submission requirements](https://www.kaggle.com/c/bluebook-for-bulldozers/overview/evaluation), we see that if we wanted to make a submission, the data is required to be in a certain format. Namely, a DataFrame containing the `SalesID` and the predicted `SalePrice` of the bulldozer.\n",
    "\n",
    "Let's make it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame compatible with Kaggle submission requirements\n",
    "df_preds = pd.DataFrame()\n",
    "df_preds[\"SalesID\"] = df_test[\"SalesID\"]\n",
    "df_preds[\"SalePrice\"] = test_preds\n",
    "df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv...\n",
    "#df_preds.to_csv(\"../data/bluebook-for-bulldozers/predictions.csv\",\n",
    "#                index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Since we've built a model which is able to make predictions. The people you share these predictions with (or yourself) might be curious of what parts of the data led to these predictions.\n",
    "\n",
    "This is where **feature importance** comes in. Feature importance seeks to figure out which different attributes of the data were most important when it comes to predicting the **target variable**.\n",
    "\n",
    "In our case, after our model learned the patterns in the data, which bulldozer sale attributes were most important for predicting its overall sale price?\n",
    "\n",
    "Beware: the default feature importances for random forests can lead to non-ideal results.\n",
    "\n",
    "To find which features were most important of a machine learning model, a good idea is to search something like \"\\[MODEL NAME\\] feature importance\".\n",
    "\n",
    "Doing this for our `RandomForestRegressor` leads us to find the `feature_importances_` attribute.\n",
    "\n",
    "Let's check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find feature importance of our best model\n",
    "ideal_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Seaborn package in current environment (if you don't have it)\n",
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Helper function for plotting feature importance\n",
    "def plot_features(columns, importances, n=20):\n",
    "    df = (pd.DataFrame({\"features\": columns,\n",
    "                        \"feature_importance\": importances})\n",
    "          .sort_values(\"feature_importance\", ascending=False)\n",
    "          .reset_index(drop=True))\n",
    "    \n",
    "    sns.barplot(x=\"feature_importance\",\n",
    "                y=\"features\",\n",
    "                data=df[:n],\n",
    "                orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(X_train.columns, ideal_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(ideal_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ProductSize.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ProductSize.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Turbocharged.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Thumb.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
